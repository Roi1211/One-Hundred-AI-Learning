{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f730d725978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "img = cv2.imread(\"Capture.PNG\",1)\n",
    "\n",
    "plt.figure(figsize = (20,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisrt Test by ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 100 # 訓練的 epochs 數量\n",
    "\n",
    "IMAGE_SIZE = (32, 32)\n",
    "\n",
    "# 凍結網路層數\n",
    "FREEZE_LAYERS = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_train shape: (50000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1, 1, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 10)           20490       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
    "# train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "#                                    width_shift_range=0.2,\n",
    "#                                    height_shift_range=0.2,\n",
    "#                                    shear_range=0.2,\n",
    "#                                    zoom_range=0.2,\n",
    "#                                    channel_shift_range=10,\n",
    "#                                    horizontal_flip=True,\n",
    "#                                    fill_mode='nearest')\n",
    "\n",
    "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
    "# 捨棄 ResNet50 頂層的 fully connected layers\n",
    "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# 增加 DropOut layer\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
    "output_layer = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
    "\n",
    "# 設定凍結與要進行訓練的網路層\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "for layer in net_final.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in net_final.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
    "net_final.compile(optimizer=Adam(),#lr=1e-3),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 輸出整個網路結構\n",
    "print(net_final.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 53s 1ms/sample - loss: 1.9226 - acc: 0.4362 - val_loss: 23.7543 - val_acc: 0.1572\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 1.9796 - acc: 0.4126 - val_loss: 2.2505 - val_acc: 0.3234\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 1.6523 - acc: 0.4702 - val_loss: 1.3205 - val_acc: 0.5212\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 1.4191 - acc: 0.5419 - val_loss: 1.6610 - val_acc: 0.5280\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 43s 863us/sample - loss: 1.1124 - acc: 0.6230 - val_loss: 1.0515 - val_acc: 0.6289\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.8972 - acc: 0.6949 - val_loss: 1.2015 - val_acc: 0.6094\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.8026 - acc: 0.7291 - val_loss: 1.1082 - val_acc: 0.6357\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.7484 - acc: 0.7493 - val_loss: 1.1753 - val_acc: 0.6398\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.7159 - acc: 0.7615 - val_loss: 0.9252 - val_acc: 0.7011\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.5889 - acc: 0.8020 - val_loss: 1.3673 - val_acc: 0.6161\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.5504 - acc: 0.8167 - val_loss: 0.8229 - val_acc: 0.7329\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.5096 - acc: 0.8306 - val_loss: 1.0407 - val_acc: 0.7043\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.4764 - acc: 0.8431 - val_loss: 1.2491 - val_acc: 0.6688\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.4176 - acc: 0.8629 - val_loss: 0.9244 - val_acc: 0.7264\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.3431 - acc: 0.8871 - val_loss: 0.9797 - val_acc: 0.7321\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.2952 - acc: 0.9012 - val_loss: 0.8879 - val_acc: 0.7619\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.2337 - acc: 0.9233 - val_loss: 1.2555 - val_acc: 0.6845\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.2136 - acc: 0.9291 - val_loss: 1.0059 - val_acc: 0.7454\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 43s 862us/sample - loss: 0.4047 - acc: 0.8758 - val_loss: 0.8185 - val_acc: 0.7749\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 43s 863us/sample - loss: 0.2204 - acc: 0.9296 - val_loss: 0.9010 - val_acc: 0.7739\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.1427 - acc: 0.9536 - val_loss: 1.1447 - val_acc: 0.7548\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.1279 - acc: 0.9576 - val_loss: 1.1835 - val_acc: 0.7446\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1218 - acc: 0.9611 - val_loss: 1.9351 - val_acc: 0.6523\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1205 - acc: 0.9614 - val_loss: 1.1949 - val_acc: 0.7348\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1892 - acc: 0.9445 - val_loss: 3.1976 - val_acc: 0.4955\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.4697 - acc: 0.8707 - val_loss: 0.8230 - val_acc: 0.7806\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1106 - acc: 0.9642 - val_loss: 0.9317 - val_acc: 0.7946\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0731 - acc: 0.9760 - val_loss: 1.6913 - val_acc: 0.6928\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1334 - acc: 0.9594 - val_loss: 1.1561 - val_acc: 0.7575\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0838 - acc: 0.9738 - val_loss: 1.0960 - val_acc: 0.7805\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0809 - acc: 0.9737 - val_loss: 1.2725 - val_acc: 0.7611\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0835 - acc: 0.9745 - val_loss: 1.1597 - val_acc: 0.7681\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0923 - acc: 0.9723 - val_loss: 1.2411 - val_acc: 0.7658\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0899 - acc: 0.9723 - val_loss: 1.1149 - val_acc: 0.7774\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0671 - acc: 0.9778 - val_loss: 1.4288 - val_acc: 0.7288\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0705 - acc: 0.9785 - val_loss: 1.4229 - val_acc: 0.7363\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0671 - acc: 0.9786 - val_loss: 1.2179 - val_acc: 0.7773\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0697 - acc: 0.9783 - val_loss: 1.2161 - val_acc: 0.7715\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0653 - acc: 0.9798 - val_loss: 1.2834 - val_acc: 0.7511\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0630 - acc: 0.9807 - val_loss: 1.2582 - val_acc: 0.7722\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0588 - acc: 0.9818 - val_loss: 1.3316 - val_acc: 0.7604\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 43s 863us/sample - loss: 0.0551 - acc: 0.9830 - val_loss: 1.3386 - val_acc: 0.7542\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0659 - acc: 0.9808 - val_loss: 1.7456 - val_acc: 0.7586\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 43s 863us/sample - loss: 0.1372 - acc: 0.9599 - val_loss: 1.1897 - val_acc: 0.7767\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0825 - acc: 0.9763 - val_loss: 1.3220 - val_acc: 0.7633\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0370 - acc: 0.9888 - val_loss: 1.4870 - val_acc: 0.7608\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0484 - acc: 0.9850 - val_loss: 1.1953 - val_acc: 0.7835\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0473 - acc: 0.9851 - val_loss: 1.3350 - val_acc: 0.7791\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0422 - acc: 0.9862 - val_loss: 1.3566 - val_acc: 0.7646\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0487 - acc: 0.9849 - val_loss: 1.5223 - val_acc: 0.7608\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1129 - acc: 0.9687 - val_loss: 1.3176 - val_acc: 0.7605\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0533 - acc: 0.9845 - val_loss: 1.1730 - val_acc: 0.7932\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0325 - acc: 0.9898 - val_loss: 1.4032 - val_acc: 0.7721\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0365 - acc: 0.9893 - val_loss: 1.3550 - val_acc: 0.7710\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0413 - acc: 0.9874 - val_loss: 1.2392 - val_acc: 0.7912\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0597 - acc: 0.9827 - val_loss: 2.0509 - val_acc: 0.6988\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1651 - acc: 0.9551 - val_loss: 1.1154 - val_acc: 0.7910\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0233 - acc: 0.9929 - val_loss: 1.4793 - val_acc: 0.7884\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 43s 868us/sample - loss: 0.0259 - acc: 0.9917 - val_loss: 1.3651 - val_acc: 0.7768\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0314 - acc: 0.9906 - val_loss: 1.7626 - val_acc: 0.7374\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0399 - acc: 0.9878 - val_loss: 1.3974 - val_acc: 0.7768\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0679 - acc: 0.9818 - val_loss: 1.5729 - val_acc: 0.7626\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0325 - acc: 0.9903 - val_loss: 1.4422 - val_acc: 0.7736\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0412 - acc: 0.9879 - val_loss: 1.5449 - val_acc: 0.7369\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.2019 - acc: 0.9569 - val_loss: 2.6872 - val_acc: 0.6831\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.1966 - acc: 0.9471 - val_loss: 1.0232 - val_acc: 0.7910\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0614 - acc: 0.9825 - val_loss: 1.3139 - val_acc: 0.7852\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0433 - acc: 0.9893 - val_loss: 1.2825 - val_acc: 0.7833\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0465 - acc: 0.9861 - val_loss: 1.3580 - val_acc: 0.7946\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0197 - acc: 0.9938 - val_loss: 1.7005 - val_acc: 0.7807\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0442 - acc: 0.9877 - val_loss: 1.6495 - val_acc: 0.7390\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 43s 868us/sample - loss: 0.0307 - acc: 0.9902 - val_loss: 1.5212 - val_acc: 0.7819\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0850 - acc: 0.9763 - val_loss: 1.1340 - val_acc: 0.7822\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0349 - acc: 0.9892 - val_loss: 1.3260 - val_acc: 0.7937\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0329 - acc: 0.9906 - val_loss: 7.9432 - val_acc: 0.7352\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.1272 - acc: 0.9690 - val_loss: 1.9501 - val_acc: 0.7762\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0340 - acc: 0.9899 - val_loss: 1.3299 - val_acc: 0.7910\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.2532 - acc: 0.9411 - val_loss: 1.1286 - val_acc: 0.7850\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0621 - acc: 0.9826 - val_loss: 1.2946 - val_acc: 0.7950\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 43s 863us/sample - loss: 0.0162 - acc: 0.9950 - val_loss: 1.4799 - val_acc: 0.7968\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0159 - acc: 0.9950 - val_loss: 1.4621 - val_acc: 0.7943\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0173 - acc: 0.9947 - val_loss: 1.5877 - val_acc: 0.7802\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0240 - acc: 0.9926 - val_loss: 1.5068 - val_acc: 0.7768\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0399 - acc: 0.9876 - val_loss: 1.3718 - val_acc: 0.7803\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0381 - acc: 0.9884 - val_loss: 1.3533 - val_acc: 0.7879\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.0253 - acc: 0.9920 - val_loss: 1.5846 - val_acc: 0.7784\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0258 - acc: 0.9921 - val_loss: 1.6067 - val_acc: 0.7731\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0309 - acc: 0.9903 - val_loss: 1.6342 - val_acc: 0.7697\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0448 - acc: 0.9874 - val_loss: 1.3096 - val_acc: 0.7945\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 43s 868us/sample - loss: 0.0301 - acc: 0.9903 - val_loss: 1.2939 - val_acc: 0.7966\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 43s 868us/sample - loss: 0.0215 - acc: 0.9936 - val_loss: 1.4504 - val_acc: 0.7924\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0298 - acc: 0.9907 - val_loss: 1.4518 - val_acc: 0.7855\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 43s 867us/sample - loss: 0.0293 - acc: 0.9916 - val_loss: 1.4502 - val_acc: 0.7871\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 43s 869us/sample - loss: 0.0261 - acc: 0.9919 - val_loss: 2.0571 - val_acc: 0.7261\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 43s 868us/sample - loss: 0.0304 - acc: 0.9912 - val_loss: 1.8610 - val_acc: 0.7482\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0251 - acc: 0.9927 - val_loss: 1.4315 - val_acc: 0.7868\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0592 - acc: 0.9839 - val_loss: 1.2863 - val_acc: 0.7740\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0384 - acc: 0.9895 - val_loss: 1.4164 - val_acc: 0.7780\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.0219 - acc: 0.9933 - val_loss: 1.3725 - val_acc: 0.7911\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.0128 - acc: 0.9963 - val_loss: 1.9864 - val_acc: 0.7553\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "# net_final.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "#                         steps_per_epoch=ceil(len(x_train) / batch_size), \n",
    "#                         epochs=epochs,\n",
    "#                         validation_data=train_datagen.flow(x_test, y_test, batch_size=batch_size),\n",
    "#                         validation_steps=ceil(len(x_test) / batch_size),\n",
    "#                         verbose=1)\n",
    "\n",
    "history = net_final.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料集並作前處理\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 16)   1040        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   1088        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   1040        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   1088        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 16)   1040        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 64)   1088        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 16)   1040        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 16)   2320        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   1088        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 64)   0           add_6[0][0]                      \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 16)   1040        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2320        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 16)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   1088        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 64)   0           add_7[0][0]                      \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 64)   256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   4160        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 64)   36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 128)  8320        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  8320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 128)  0           conv2d_30[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 64)   8256        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 128)  8320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 64)   8256        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 64)   36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 64)   256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 64)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 128)  8320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 64)   8256        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 64)   36928       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 128)  8320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 128)  0           add_11[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 128)  512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 64)   8256        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 64)   256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 64)   36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 64)   256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 128)  8320        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 128)  0           add_12[0][0]                     \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 128)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 64)   8256        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 64)   36928       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  8320        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 128)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 128)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 64)   8256        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 64)   256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 64)   36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 64)   256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 128)  8320        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 128)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 128)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 64)   8256        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 64)   256         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 64)   36928       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 128)  8320        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 128)  0           add_15[0][0]                     \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 128)  512         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 128)    16512       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 128)    512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 128)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 128)    147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 128)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 256)    33024       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 256)    33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 256)    0           conv2d_55[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 128)    32896       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 128)    512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 128)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 128)    147584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 256)    33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 256)    0           add_17[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 128)    32896       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 128)    512         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 128)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 128)    147584      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 128)    512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 128)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 256)    33024       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 256)    0           add_18[0][0]                     \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 256)    1024        add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 256)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 128)    32896       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 128)    512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 128)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 128)    147584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 128)    512         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 128)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 256)    33024       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 256)    0           add_19[0][0]                     \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 256)    1024        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 256)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 128)    32896       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 128)    512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 128)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 128)    147584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 128)    512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 128)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 256)    33024       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 256)    0           add_20[0][0]                     \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 256)    1024        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 256)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 128)    32896       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 128)    512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 128)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 128)    147584      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 128)    512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 128)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 256)    33024       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 256)    0           add_21[0][0]                     \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 256)    1024        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 256)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 128)    32896       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 128)    512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 128)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 128)    147584      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 128)    512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 128)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 256)    33024       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 256)    0           add_22[0][0]                     \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 256)    1024        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 256)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 128)    32896       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 128)    512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 128)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 128)    147584      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 128)    512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 128)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 256)    33024       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 8, 8, 256)    0           add_23[0][0]                     \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 256)    1024        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 256)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2570        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,223,562\n",
      "Trainable params: 2,209,706\n",
      "Non-trainable params: 13,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立 ResNet 模型\n",
    "\n",
    "resnet_N = 8\n",
    "model = resnet(input_shape=(32,32,3), depth=9*resnet_N+2) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 透過 data augmentation 產生訓練與驗證用的影像資料\n",
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此函數會幫我們把多張影像畫成一張多宮格圖\n",
    "def img_combine(img, ncols=8, size=1, path=False):\n",
    "    from math import ceil\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    nimg = len(img)\n",
    "    nrows = int(ceil(nimg/ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(ncols*size,nrows*size))\n",
    "    if nrows == 0:\n",
    "        return\n",
    "    elif ncols == 1:\n",
    "        for r, ax in zip(np.arange(nrows), axes):\n",
    "            nth=r\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "                \n",
    "            ax.set_axis_off()\n",
    "    elif nrows == 1:\n",
    "        for c, ax in zip(np.arange(ncols), axes):\n",
    "            nth=c\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "            ax.set_axis_off()\n",
    "    else:\n",
    "        for r, row in zip(np.arange(nrows), axes):\n",
    "            for c, ax in zip(np.arange(ncols), row):\n",
    "                nth=r*ncols+c\n",
    "                if nth < nimg:\n",
    "                    ax.imshow(img[nth], cmap='rainbow', vmin=0, vmax=1)\n",
    "                ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAADnCAYAAACTx2bHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAD/klEQVR4nO3cMa6rQBAF0deW979k9w/IcWWA/zkpBHPloDSSxezuHwBw7nX1AQDgCQQTAALBBIBAMAEgEEwACN5nD2fm0X+h3d359s7/sPH1ej164+fz8Tv+2fgENh5+daMbJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQCCYABAIJgAEggkAgWACQDC7e/UZAOD23DABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSA4H32cGYe/VWD3Z1v79h4fzYebLw/Gw+/utENEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAQDABIBBMAAgEEwACwQSAYHb36jMAwO25YQJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJA8D57ODOP/gzQ7s63d2y8PxsPNt6fjYdf3eiGCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAIJgAEAgmAASCCQCBYAJAMLt79RkA4PbcMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgeJ89nJlHfwZod+fbOzben40HG+/PxsOvbnTDBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgEEwACAQTAALBBIBAMAEgmN29+gwAcHtumAAQCCYABIIJAIFgAkAgmAAQCCYABP8AmAGQw2W+9rUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 32 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "augmented_iamges = next(train_datagen.flow(x_train, shuffle=False))\n",
    "img_combine(augmented_iamges.astype(\"int\")) # 注意在訓練時神經網路時，圖像資料必須要是 float32，但在做視覺化時要轉為 int 才能順利畫圖。所以為了畫圖才把資料轉為 int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "782/782 [==============================] - 88s 113ms/step - loss: 3.0586 - accuracy: 0.1328 - val_loss: 2.6072 - val_accuracy: 0.1352\n",
      "Epoch 2/100\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 2.4821 - accuracy: 0.1349 - val_loss: 2.3491 - val_accuracy: 0.1466\n",
      "Epoch 3/100\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 2.3726 - accuracy: 0.1389 - val_loss: 2.6909 - val_accuracy: 0.1196\n",
      "Epoch 4/100\n",
      " 31/782 [>.............................] - ETA: 1:05 - loss: 2.3521 - accuracy: 0.1386"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5a3d10c5bdb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                               verbose=1)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 100 # 訓練整個資料集共 30個循環\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(x_train, y_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(x_test, y_test))\n",
    "\n",
    "history = model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n",
    "                              steps_per_epoch=ceil(len(x_train) / batch_size), \n",
    "                              epochs=epochs,\n",
    "                              validation_data=train_datagen.flow(x_test, y_test, batch_size=batch_size, shuffle=True),\n",
    "                              validation_steps=ceil(len(x_test) / batch_size),\n",
    "                              verbose=1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
